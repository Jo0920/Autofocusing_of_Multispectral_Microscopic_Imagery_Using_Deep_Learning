# reference path
reference_image_path: ...
reference_test_path: ...

# data path
train_image_path_gray: ...
test_image_path_gray: ...

train_image_path_cycle: ...
test_image_path_cycle: ...

# origin data path
data_path_origin: ...

# model path
cat_saved_model_path_deterministic: ...
cat_saved_model_path_bayesian: ...
cat_model_name_generator: ...
cat_model_name_discriminator: ...

cat_save_to: ...

# dataset setting
start_data: 1 # the first focus to be trained
end_data: 31 # the last focus to be trained
spectrum_num: 6 # num of spectrum (>=2)

# general train setting
epoch: 9 # epoch to start training from
n_epoch: 20 # number of epochs of training ## !!Epoch should be LARGER if batch size>1
train_dataset_name: HSI # name of the dataset
batch_size: 1 # size of the batches
img_num: 1 # number of images loaded once
b1: 0.9 # adam: decay of first order momentum of gradient
b2: 0.999 # adam: decay of second order momentum of gradient
n_cpu: 14 # number of cpu threads to use during batch generation
patch_height: 256 # size of patch height
patch_width: 256 # size of patch width
img_height: 1536 # size of image height
img_width: 2048 # size of image width
channels: 3 # number of image channels
checkpoint_interval: 1 # interval between model checkpoints

# concatenate setting
cat_preprocess: False
cat_dataset_name: full

# pix2pix setting
lr_g: 0.0002 # adam: learning rate
lr_d: 0.0002 # adam: learning rate
lambda_pixel: 10 # lambda of loss_g

# cycle setting
w_d: 0.0001  # adamW: weight decay
lr_g_x: 0.0002 # adam: learning rate
lr_d_x: 0.0002 # adam: learning rate
lr_g_y: 0.0002 # adam: learning rate
lr_d_y: 0.0002 # adam: learning rate